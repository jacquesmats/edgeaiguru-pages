<?xml version="1.0" encoding="utf-8"?>

<feed xmlns="http://www.w3.org/2005/Atom" >
  <generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator>
  <link href="http://localhost:4000/tag/back-to-basics/feed.xml" rel="self" type="application/atom+xml" />
  <link href="http://localhost:4000/" rel="alternate" type="text/html" />
  <updated>2020-06-16T14:42:55-03:00</updated>
  <id>http://localhost:4000/tag/back-to-basics/feed.xml</id>

  
  
  

  
    <title type="html">Edge AI Guru | </title>
  

  
    <subtitle>The guidance through your Artificial Intelligence journey</subtitle>
  

  

  
    
      
    
  

  
  

  
    <entry>
      <title type="html">Gradient Descent, Feedforward and Backpropagation</title>
      <link href="http://localhost:4000/Feedforward-and-Backpropagation" rel="alternate" type="text/html" title="Gradient Descent, Feedforward and Backpropagation" />
      <published>2020-06-15T07:15:00-03:00</published>
      <updated>2020-06-15T07:15:00-03:00</updated>
      <id>http://localhost:4000/Feedforward%20and%20Backpropagation</id>
      <content type="html" xml:base="http://localhost:4000/Feedforward-and-Backpropagation">&lt;p&gt;Let’s see three fundamentals concepts of Deep Learning: the Gradient Descent, Feedforward and Backpropagation steps.&lt;/p&gt;

&lt;p&gt;Versão em português disponível em 26 de Junho &lt;a href=&quot;http://edgeaiguru.com/404&quot;&gt;aqui&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/feed-back-prop/pre-cover.png&quot; alt=&quot;image-20200607150421443&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;gradient-descent&quot;&gt;Gradient Descent&lt;/h2&gt;

&lt;p&gt;Gradient Descent(GD)  in one of the most common algorithms that help the Neural Networks to reach the correct values of weights and bias. To illustrate this method, let’s take a look at a Logistic Regression model. In this model, we have a loss of L(ŷ,y), where it defines how far the predicted output is from the correct output. If we sum all the losses during the training phase and average them, we will get the Cost Function J(w,b).  What is usually used for regression problems is the following:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/feed-back-prop/log-reg-loss-function.png&quot; alt=&quot;image-20200607150421443&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Since we want to train our model to be as much accurate as possible, it is natural that this method tries to minimize the Cost Function J(W,b) in each step. So the cost function measures how well the parameters W and b are performing in the training set, iteratively updating the weights and bias trying to reach the global minimum in such function. And what is a global minimum? As shown in the figure below, the global minimum of a function J(theta1,theta2) is the values of theta1 and theta2 that produce the minimum value on J. Here J is equivalent to the height of the plot. Notice that there is the so-called local minimum, which sometimes tricks the model making it believe it has achieved the global minimum. One can be seen at theta1 and theta2 equals 0.8.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/gradient-descent-variants/gradient-descent.png&quot; alt=&quot;Gradient descent to minimize cost function&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Minimizing the Cost Function, a Gradient Descent Illustration. Source: &lt;a href=&quot;https://www.coursera.org/learn/machine-learning&quot;&gt;Stanford’s Andrew Ng’s MOOC Machine Learning Course&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;So, the minimum is dependent on the cost function J chosen, and to achieve it, we must first define some starting point for W and b and try to go downhill in the direction of the steepest descent in the function. To make it easy to understand, let us take a look at just one variable. If we are trying to minimize the function J(w), as shown below, and we initialize W with a very high value on the X-axis, what are the next steps?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/feed-back-prop/cost-function-j-w-1.png&quot; alt=&quot;Cost Function 1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To update the weight W and the bias b, the gradient descent rule is as follows:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/gradient-descent-variants/f1.png&quot; alt=&quot;math1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To move it to the minimum, we first need to know which direction we should follow. Should we increase or decrease W? This can be achieved with the derivative of the point. A derivative is a calculus tool that is equal to the slope of the function at a given point. In other words, it tells us exactly what we need to know: the direction we should follow. When the function is increasing the derivative is positive, when the function is decreasing it is negative and when it is zero it means that it reached a local or global minimum. In the following figure, the derivative in this point is positive and so the dW value will be subtracted from W, in the formula above, and we are going to move left.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/feed-back-prop/cost-function-j-w-2.png&quot; alt=&quot;Cost Function 2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;On the other hand, if W was a low number on the left side of the figure, the derivative would be negative and the number dW would be added to W, moving it to the right. The alpha term is called Learning Rate and it defines how big those steps would be. Defining it too big could make the function pass through the local minimum and start to diverge.&lt;/p&gt;

&lt;p&gt;This is a simple convex function analyzed in a 2D graph. Although the concepts and steps remain the same, depending on the problem these functions could get pretty complex and have multiple dimensions, and it is even harder to visualize it. As you may see later, the Gradient Descent is just one of several Optimization Algorithms such as Adagrad, Adadelta, RMSProp, Momentum, and Adam.&lt;/p&gt;

&lt;p&gt;So now we have an optimization algorithm to update W and b values to get our model output closer to the expected output. Through the &lt;strong&gt;Forward Propagation&lt;/strong&gt;, we will pass through the model and calculate an output value (the prediction), compare this value with the expected output, and find an error. With this, we will transmit this error backward using &lt;strong&gt;Backward Propagation&lt;/strong&gt; and with the gradients (derivative values) to update the values for W and b, making the whole model closer to the cost function’s global minimum.&lt;/p&gt;

&lt;h2 id=&quot;feedforward&quot;&gt;Feedforward&lt;/h2&gt;

&lt;p&gt;It is the phase we calculate the model output, so we can understand how accurate it is. For illustration, lets take a network with just one hidden layer. In practice we may have several hidden layers and multiple output values. We will have to calculate the hidden states and then find the output values based on this states. Here the hidden layer and the outputs are matrices and we denote the layer by adding square brackets, i.e. [1] it’s the first layer. To calculate the predict output (ŷ) in the following 2 layers network, we must first find hidden values here called z.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/feed-back-prop/feedforward.png&quot; alt=&quot;Feedforward&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Each hidden neuron is divide into two operations: the linear function y = x*w + b and the application of an activation function sigma. These steps are named s and z, respectively. In this example, we are going to set b, or bias, to zero to simplify the explanation. We use activation functions to make sure these values do not increase too much. It will make sure the outputs are between 0 and 1 or -1 and 1 (check this post for more about activation functions). Furthermore, these functions allow the network to represent nonlinear relationships between inputs and outputs.&lt;/p&gt;

&lt;p&gt;So initializing randomly the weights W and choosing TanH as an activation function sigma, we have:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/feed-back-prop/random-weights-sigma.png&quot; alt=&quot;image-20200614105546474&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We will assume that in this particular training step, we are inputing x1 and x2 equals 1 and are expecting the model to output 1 as well. As state before, the first step is to calculate the result of the linear function and find s1 and s2 from the first layer [1]. Then, the results are passed through an activation function to serve as inputs for the next layer.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/feed-back-prop/s-and-z-output.png&quot; alt=&quot;image-20200614112302494&quot; /&gt;&lt;/p&gt;

&lt;p&gt;With z1 and z2 in hands, we can now calculate the input from the next layer, in this case, the output layer. Multiplying these values by the weights and passing through the tanh activation function, we finally find our predicted output:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/feed-back-prop/predicted-output.png&quot; alt=&quot;image-20200614112507065&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In the output layer, sometimes we use different activation functions, or none, depending on the application. If it was a classification problem, we could use a Softmax here.&lt;/p&gt;

&lt;p&gt;With the predicted output, we can now calculate the error. The error can be as simple as the predicted minus the expected output (ŷ - y), or the squared error = (y_pred - y)². The Mean Squared Error (MSE) is sometimes used in regression problems, while the cross-entropy is used for classification problems. This function is called the Loss Function and once again, it depends on the problem we are trying to solve. That represents how good our model is performing, lower the value, closer we are to the expected output value.&lt;/p&gt;

&lt;p&gt;We will use the MSE here for sake of simplicity since MSE makes the gradient descent not work well. In logistic regression is common to use the loss function demonstrated at the beginning of this post, because it gives us a convex optimization problem.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/feed-back-prop/mse.png&quot; alt=&quot;Mean Squared Error &quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;backpropagation&quot;&gt;Backpropagation&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/feed-back-prop/backpropagation.png&quot; alt=&quot;Backpropagation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It is the phase we take the error and adjust the weights so in the next iteration we have a small error. We must then go back adjusting the weights based on this MSE error. The backpropagation step is the SGD with the Chain Rule from Calculus. With partial derivatives, we can understand how the error is impacted by each weight separately.&lt;/p&gt;

&lt;h3 id=&quot;the-chain-rule-and-partial-derivatives&quot;&gt;The chain rule and partial derivatives&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/feed-back-prop/chain-rule.png&quot; alt=&quot;Chain Rule&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The chain rule is actually very intuitive: if we have A, which apply a function f to a variable x and B, where another function g applies a function over f(x), the chain rule says that if we want to find the partial derivative of B with respect to x we should multiply the intermediary partial derivatives.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/feed-back-prop/partial-derivatives.png&quot; alt=&quot;Partial Derivatices&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;updating-the-weights-with-backpropagation&quot;&gt;Updating the weights with backpropagation&lt;/h3&gt;

&lt;p&gt;Our main focus in Machine Learning is to update the weights so that the model gives us better predictions. The general rule for updating the weights and bias was showed before, but for this example we are setting ‘b’ to zero, so we only have to update W:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/feed-back-prop/update-w.png&quot; alt=&quot;Update Rule GD&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So, to achieve this we need to find the partial derivative of the Loss Function L(ŷ, y) with respect to W, and this update function can be applied to any weight in the figure above. In this post, we are not going to dive deep in how derivatives works and I’ll show you only what is the value of certain derivative. Although we must understand how all this process works, the most common Deep Learning Frameworks already had this implement and would be very rare the case you are going to code this.&lt;/p&gt;

&lt;p&gt;For the sake of illustration, let’s find the new value to w12. And for that, lets state two things: we chose the Median Square Error as loss function and the hyperbolic tangent as activation function. The derivative of z[2] with respect of s[2] is equal the derivative of the activation function tanh, so:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/feed-back-prop/loss-function-mse.png&quot; alt=&quot;MSE Loss Function&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/feed-back-prop/derivative-tanh.png&quot; alt=&quot;Derivative of Hyperbolic Tangent&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The first step is to calculate how the loss was influenced by the activation step in z[2]. We achieve this finding the derivative of the loss function with respect to z[2]:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/feed-back-prop/dz2.png&quot; alt=&quot;image-20200615210236714&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Next we calculate how the loss was impacted by s[2], through the chain rule. This is equal to the partial derivative of the previous case, multiplied by the derivative of z[2] with respect of s[2], which is the derivative of the activation function state above.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/feed-back-prop/ds2.png&quot; alt=&quot;image-20200615210913075&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And finally, to find the derivative we were looking for, to update w12, we keep following the chain to find the derivative of the cost function with respect of w12. Here ds/dw is equal to the derivative of the linear function (s) with respect a w, where x is the term from W is multiplied for. In the weight w[2]12 is z[1]1, and in the w[1]11 is x1, for exemple.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/feed-back-prop/ds-dw.png&quot; alt=&quot;image-20200615211707555&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/feed-back-prop/dw12.png&quot; alt=&quot;image-20200615212010762&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now we have the term needed (dL(ŷ,y) / dW) to update the weight w[2]12. This value is called the gradient and tells us in which direction and how big this step should be.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/feed-back-prop/dw12-num.png&quot; alt=&quot;image-20200615213452203&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And choosing a learning rate alpha of 0.1, the new value for the weight w12 would be:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/feed-back-prop/dw12-updated.png&quot; alt=&quot;image-20200615214024309&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This would change the weight so that the error would be lower in the following iteration. Then we would update again this weight in a iterative process until the model as a whole has the right weights to make a prediction. I won’t be showing all the weights numerically, but here are all the derivatives needed to calculate all the weights:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/feed-back-prop/all-weights-derivatives.png&quot; alt=&quot;All the weights derivatives&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;next-steps&quot;&gt;Next steps&lt;/h2&gt;

&lt;p&gt;Awesome! Now you know a little bit more how Deep Learning models work under the hood. There are amazing resources online where you can continue to learn and create a deep understanding of these concepts. The &lt;a href=&quot;https://www.coursera.org/learn/neural-networks-deep-learning&quot;&gt;Andrew Ng MOOC&lt;/a&gt; is the go-to course to understand deeply the theoretical part of Deep Learning and have assignments to consolidate your knowledge through programming exercises.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Would you like to  receive the most important news and trends in AI in just one email every end of the month? Subscribe below and I’ll send you the 10 most important news in Artificial Intelligence.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Matheus Jacques</name>
        
        
      </author>

      

      
        <category term="back-to-basics" />
      

      
        <summary type="html">Let’s see three fundamentals concepts of Deep Learning: the Gradient Descent, Feedforward and Backpropagation steps.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Introduction to Neural Networks</title>
      <link href="http://localhost:4000/Introduction-to-Neural-Networks" rel="alternate" type="text/html" title="Introduction to Neural Networks" />
      <published>2020-05-03T07:18:00-03:00</published>
      <updated>2020-05-03T07:18:00-03:00</updated>
      <id>http://localhost:4000/Introduction%20to%20Neural%20Networks</id>
      <content type="html" xml:base="http://localhost:4000/Introduction-to-Neural-Networks">&lt;p&gt;Learn the main concepts behind Neural Networks, one of Deep Learning’s pillars.&lt;/p&gt;

&lt;p&gt;Versão em português &lt;a href=&quot;http://edgeaiguru.com/Introdução-a-Redes-Neurais&quot;&gt;aqui&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Artificial Intelligence has been revolutionizing the industry in recent years and solving problems, which previously were costly in time and money, much more effectively. Computer vision problems, natural language processing, and several other applications are only possible thanks to advances in Deep Learning.&lt;/p&gt;

&lt;p&gt;Artificial Neural Networks (ANN) are one of the main pillars of this technology. Inspired by the human brain, ANN carries this name because of its biological connections and motivations. Just as in the human brain, where the most basic processing unit is the neuron, ANNs have an element that processes impulses, or inputs, which is also called a neuron or node.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/nn-intro/artificial-vs-biological-neuron.png&quot; alt=&quot;Artificial vs Biological Neuron&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Biological Neuron vs Artificial Neuron. Source: [Keras Tutorial: Deep Learning in Python] (https://www.datacamp.com/community/tutorials/deep-learning-python)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Both structures share the same function for transferring information: they receive an input (impulse) that is carried through the node (cell body) and activate a certain output (axon terminals). Just as in biological neurons, this impulse that fires neurons is reproduced in ANNs through activation functions.&lt;/p&gt;

&lt;p&gt;Therefore, this basic element of neural networks can be represented by the following figure, taken from the course &lt;a href=&quot;https://www.coursera.org/learn/neural-networks-deep-learning&quot;&gt;Neural Networks and Deep Learning&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/nn-intro/generic-neuron.png&quot; alt=&quot;Generic Neuron&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Where, through the example of the necessity to predict the price of houses based on their size, we can determine a function that can represent this problem. In this example, a ReLU function fits the data perfectly. So, the minimum representation of a neuron would be input the house’s area and, based on the mathematical function stored “inside” the neuron, we can estimate a price for that residence.&lt;/p&gt;

&lt;p&gt;In this way, we train each neuron to be activated when a certain pattern appears. Thus, grouping several neurons in series and parallel, allows Neural Networks to learn to recognize patterns in images, texts, audios, and in the most distinct forms of data.&lt;/p&gt;

&lt;p&gt;In this article, the main components of Artificial Neural Networks, some of the main architectures and the most common activation functions will be presented.&lt;/p&gt;

&lt;h2 id=&quot;artificial-neural-networks-ann&quot;&gt;Artificial Neural Networks (ANN)&lt;/h2&gt;

&lt;p&gt;Although neural networks have some similarities to neurons in the human brain, they are infinitely simpler than their biological counterpart. These architectures are composed of mathematical blocks that can be explained using algebra and calculus, very different from the different parts of the brain that are not yet understood.&lt;/p&gt;

&lt;p&gt;The main components of ANNs are input layers, hidden layers, and output layers. These layers are activated through weighted connections, which defines how important the connection is to the network. In addition, as we saw earlier, at the output of each neuron there is an activation function that defines whether the neuron will be fired or not.&lt;/p&gt;

&lt;h2 id=&quot;neural-networks-building-blocks&quot;&gt;Neural Networks Building Blocks&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/nn-intro/generic-2-layers-neural-network.png&quot; alt=&quot;Generic 3 Layer Neural Network&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Generic 3 Layers Neural Network Architecture. Source: [Stanford CS231n] (https://cs231n.github.io/neural-networks-1/#nn)&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;input-layer&quot;&gt;&lt;em&gt;Input Layer&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;A block of neurons can be called a layer. But note that although neurons are interconnected between layers, they do not have connections within the same layer. As shown in the figure above, the first layer of a Neural Network is the input layer. This has only the function of passing the system inputs to the next layer and does not perform any mathematical function.&lt;/p&gt;

&lt;h3 id=&quot;hidden-layers&quot;&gt;&lt;em&gt;Hidden Layers&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;This layer is responsible for one of the main functions of neural networks: to process the data and send it to the next layer. The value of each neuron is found by multiplying the weights W by the input X and adding a bias b. This value then goes through an activation function and is sent to the next layer, as shown in Fig. 2.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/nn-intro/hidden-layer-mathematics-en.png&quot; alt=&quot;Hidden Layer Mathematics&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Mathematical operations within the neuron. Source: Source: [Stanford CS231n] (https://cs231n.github.io/neural-networks-1/#nn) Modified.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Thus, if we isolate the first neuron from the first hidden layer, the output value of the neuron will be equal to z1. Where &lt;em&gt;s1&lt;/em&gt; is the neuron’s input, where we multiply the weights by the inputs and add a bias b. After this operation, a transfer function &lt;em&gt;g&lt;/em&gt; is applied over &lt;em&gt;s1&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;It is important to note that &lt;em&gt;X&lt;/em&gt; and &lt;em&gt;W&lt;/em&gt; in the first equation are matrices in this case and represent all inputs and all weights, respectively.&lt;/p&gt;

&lt;p&gt;We call this layer “Hidden Layer” because during the training of neural networks we have the inputs that are known and the outputs that are expected. But we don’t see what values are inside the neurons in that layer. This block can contain several hidden layers, and the more layers the “deeper” the neural network is, and the more patterns it can learn.&lt;/p&gt;

&lt;h3 id=&quot;output-layers&quot;&gt;&lt;em&gt;Output Layers&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;The output layer is responsible for showing the results obtained through the calculations made in the hidden layers. Usually, an activation function is used, as well as that of the neurons in the previous layers, to simplify the result.&lt;/p&gt;

&lt;h3 id=&quot;weights-and-bias&quot;&gt;&lt;em&gt;Weights and Bias&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;Weights are responsible for defining how important that connection is to the neural network. As there are several connections within the ANN, this is how this architecture understands which patterns it should learn and which ones it should ignore. In addition, a value called bias is commonly used with weights and inputs. This value helps to fine-tune the neural network. Thus, if we have a neuron i in one layer and a neuron j in the next layer, we have a connection with the weight Wij and a bij bias.&lt;/p&gt;

&lt;h3 id=&quot;activation-functions&quot;&gt;&lt;em&gt;Activation Functions&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;Also called the transfer function, it is the last mathematical processing step that takes place before the information leaves the neuron. This mathematical equation defines whether the neuron will be activated or not, which may be a step function, a linear function, or a non-linear function.&lt;/p&gt;

&lt;p&gt;The simplest activation function would be a step function. Where the neuron would activate only if the input was above a threshold, and the input signal would be fully reproduced at the node’s output.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/nn-intro/step-function.png&quot; alt=&quot;Step Function&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This can return values of 0 and 1, used in classification problems, or between 0 and 1, used in problems that we are more interested in knowing the probability of a certain entry being part of a certain class.&lt;/p&gt;

&lt;h2 id=&quot;main-types-of-artificial-neural-networks&quot;&gt;&lt;em&gt;Main Types of Artificial Neural Networks&lt;/em&gt;&lt;/h2&gt;

&lt;p&gt;There are two main types of Neural Networks: Feedforward Neural Networks and Recurrent Neural Networks.&lt;/p&gt;

&lt;h3 id=&quot;feedforward-neural-networks-fnn&quot;&gt;&lt;em&gt;Feedforward Neural Networks (FNN)&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;This architecture is the most commonly found in the literature. In it, information moves only in one direction: from the inputs, through the hidden layer to the output node, and there are no cycles.&lt;/p&gt;

&lt;p&gt;The simplest unit of this topology is called Perceptron, the most simplistic neural network that is composed of just one node.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/nn-intro/perceptron.png&quot; alt=&quot;Perceptron&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;The Perceptron&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Some simple problems can be solved with Perceptron, as it only works with linearly separable functions.&lt;/p&gt;

&lt;p&gt;With the need to solve more complex problems and from this basic unit, the &lt;strong&gt;Multilayer Perceptron (MLP)&lt;/strong&gt; was conceived. Composed of several layers of these nodes, being much more useful and being able to learn non-linear functions.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/nn-intro/multi-layer-perceptron.png&quot; alt=&quot;Multilayer Perceptron&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Multilayer Perceptron Architecture. Source: [Advanced Methods for the Processing and Analysis of Multidimensional Signals: Application to Wind Speed] (https://www.researchgate.net/figure/Architecture-of-a-multilayer-perceptron-neural-network_fig5_316351306)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;And finally, we have the &lt;strong&gt;Convolutional Neural Networks (CNN)&lt;/strong&gt;, which are the most common example of Feedforward Neural Networks. Inspired by the Visual Cortex, this topology divides data into small pieces and tries to learn essential patterns. This operation is called Convolution. More efficient than MLP, this topology is found widely in computer vision, video, and natural language applications. This topology has its own characteristic blocks, such as the convolution and pooling layers.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/nn-intro/convolution-neural-network.png&quot; alt=&quot;Convolutional Neural Network&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Convolutional Neural Network Example. Source: &lt;a href=&quot;https://missinglink.ai/guides/convolutional-neural-networks/convolutional-neural-network-tutorial-basic-advanced/&quot;&gt;Convolutional Neural Network Tutorial&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;recurring-neural-networks-rnn&quot;&gt;&lt;em&gt;Recurring Neural Networks (RNN)&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;Unlike Feedforward Neural Networks, in RNN information flows not only forward, but also backward, forming a cycle. For this, like CNN, they use several characteristical blocks, such as a memory block for example. This allows this topology to capture dynamic temporal patterns and be widely used in speech recognition problems and problems that require sequential linking.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/nn-intro/recorrent-neural-network.png&quot; alt=&quot;Recurrent Neural Network&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Example of Recurrent Neural Network. Source: &lt;a href=&quot;https://commons.wikimedia.org/wiki/File:Recurrent_neural_network_unfold.svg&quot;&gt;wikimedia&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;types-of-activation-functions&quot;&gt;Types of Activation Functions&lt;/h2&gt;

&lt;p&gt;In addition to the step function, which I believe is not used in practice, there are several other activation functions. In addition to determining the model’s output, they also help with the accuracy of the results and the efficiency training. In practice, modern models use nonlinear activation functions, which are able to capture patterns in more complex data.&lt;/p&gt;

&lt;p&gt;The activation functions are used in two moments in the Neural Networks: to process the output of a single neuron, as we saw during the topic of hidden layers, and to process the output of the neural network as a whole.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/nn-intro/sigmoid.png&quot; alt=&quot;Sigmoid Formula and Graph&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/nn-intro/tanh.png&quot; alt=&quot;Tanh Formula and Graph&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/nn-intro/relu.png&quot; alt=&quot;Relu Formula and Graph&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Normally Rectified Linear Unit (ReLU) functions are used in practice. The Sigmoid function is normally used to demonstrate how these elements work and is usually replaced by the Hyperbolic Tangent (TanH). Except in the case of the problem being a binary classification, in that case a Sigmoid function would be better in the model’s output as it would already deliver the result between 0 and 1.&lt;/p&gt;

&lt;p&gt;The choice of the activation function is motivated by the characteristics of the problem being solved. Sigmoid, for example, despite having a smoother gradient and normalizing the output between 0 and 1, has problems with vanish gradients and its output is not centered at zero. TanH has its center at zero, which facilitates the learning of the following layers, but disadvantages similar to Sigmoid.&lt;/p&gt;

&lt;p&gt;In addition to these, we can also highlight:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Leaky ReLU&lt;/li&gt;
  &lt;li&gt;Softmax&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In this article we went through some of the main concepts of Artificial Neural Networks. After this review, I hope that you already have a more concrete idea of the basic concepts that involve one of the main topics of Deep Learning. Understanding the main building blocks of ANN, the main topologies and the most common activation functions, we can now move on to more advanced topics such as &lt;strong&gt;Forward and Backward Propagation&lt;/strong&gt; and &lt;strong&gt;Gradient Descent&lt;/strong&gt;.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Matheus Jacques</name>
        
        
      </author>

      

      
        <category term="back-to-basics" />
      
        <category term="neural-networks" />
      

      
        <summary type="html">Learn the main concepts behind Neural Networks, one of Deep Learning’s pillars.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Batch vs Mini-batch vs Stochastic Gradient Descent with Code Examples</title>
      <link href="http://localhost:4000/Batch-vs-Mini-batch-vs-Stochastic-Gradient-Descent" rel="alternate" type="text/html" title="Batch vs Mini-batch vs Stochastic Gradient Descent with Code Examples" />
      <published>2020-04-26T07:18:00-03:00</published>
      <updated>2020-04-26T07:18:00-03:00</updated>
      <id>http://localhost:4000/Batch%20vs%20Mini%20batch%20vs%20Stochastic%20Gradient%20Descent</id>
      <content type="html" xml:base="http://localhost:4000/Batch-vs-Mini-batch-vs-Stochastic-Gradient-Descent">&lt;p&gt;What is the difference between these three Gradient Descent variants?&lt;/p&gt;

&lt;p&gt;One of the main questions that arises when studying Machine Learning and Deep Learning is the several types of Grandient Descent. Should I use Batch Gradient Descent? Mini-batch Gradient Descent or Stochastic Gradient Descent? In this post we are going to understand the difference between those concepts and take a look in code implementations from Gradient Descent, for the purpose of clarifying these methods.&lt;/p&gt;

&lt;p&gt;At this point, we know that our matrix of weights &lt;strong&gt;W&lt;/strong&gt; and our vector of bias &lt;strong&gt;b&lt;/strong&gt; are the core values of our Neural Networks (NN) (Check the Deep Learning Basics post). We can make an analogy with these concepts with the memory in which a NN stores patterns, and it is through tuning these parameters that we teach a NN. The acting of tuning this is done through the optimization algorithms, the amazing feature that allows NN to learn. After some time training the network, these patterns are learned and we have a set of weights and biases that hopefully correct classifies the inputs.&lt;/p&gt;

&lt;h2 id=&quot;gradient-descent&quot;&gt;&lt;strong&gt;Gradient Descent&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;One of the most common algorithms that help the NN to reach the correct values of weights and bias. The Gradient Descent (GD) is a method/algorithm to minimize the cost function J(W,b) in each step. It iteratively updates the weights and bias trying to reach the global minimum in a cost function.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/gradient-descent-variants/gradient-descent.png&quot; alt=&quot;Gradient descent to minimize cost function&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Minimizing the Cost Function, a Gradient Descent Illustration. Source: &lt;a href=&quot;https://www.coursera.org/learn/machine-learning&quot;&gt;Stanford’s Andrew Ng’s MOOC Machine Learning Course&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Review this quickly, before we can compute the GD, first the inputs are taken and passed through all the nodes of a neural network, calculating the weighted sum of inputs, weights, and bias. This first pass is one of the main steps when calculating Gradient Descent and it is called &lt;strong&gt;Forward Propagation&lt;/strong&gt;. Once we have an output, we compare this output with the expected output and calculate how far it is from each other, the error. With this error, we can now propagate it backward, updating each and every weight and bias and trying to minimize this error. And this part is called, as you may anticipate, &lt;strong&gt;Backward Propagation&lt;/strong&gt;. The Backward Propagation step is calculated using derivatives and return the “gradients”, values that tell us in which direction we should follow to minimize the cost function.&lt;/p&gt;

&lt;p&gt;We are now ready to update the weight matrix W and the bias vector b. The gradient descent rule is as follows:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/gradient-descent-variants/f1.png&quot; alt=&quot;math1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In other words, the new weight/bias value will be the last one minus the gradient, moving it close to the global minimum value of the cost function. We also multiply this gradient to a learning rate alpha, which controls how big the step would be. For a more deep approach to Forward and Backward Propagation, Compute Losses,  Gradient Descent, check this post.&lt;/p&gt;

&lt;p&gt;This classic Gradient Descent is also called Batch Gradient Descent. In this method, every epoch runs through all the training dataset, to only then calculate the loss and update the W and b values. Although it provides stable convergence and a stable error, this method uses the entire training set; hence it is very slow for big datasets.&lt;/p&gt;

&lt;h2 id=&quot;mini-batch-gradient-descent&quot;&gt;&lt;strong&gt;Mini-batch Gradient Descent&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Imagine taking your dataset and dividing it into several chunks, or batches. So instead of waiting until the algorithm runs through the entire dataset to only after update the weights and bias, it updates at the end of each, so-called, mini-batch. This allows us to move quickly to the global minimum in the cost function and update the weights and biases multiple times per epoch now. The most common mini-batch sizes are 16, 32, 64, 128, 256, and 512. Most of the projects use Mini-batch GD because it is faster in larger datasets.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Mini-batch Gradient Descent&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_input&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
	
	&lt;span class=&quot;n&quot;&gt;minibatches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_mini_batches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;

	    &lt;span class=&quot;c&quot;&gt;# Select a minibatch&lt;/span&gt;
	    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minibatch_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatch_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatch&lt;/span&gt;
	    &lt;span class=&quot;c&quot;&gt;# Forward propagation&lt;/span&gt;
	    &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	    &lt;span class=&quot;c&quot;&gt;# Compute cost.&lt;/span&gt;
	    &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compute_cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	    &lt;span class=&quot;c&quot;&gt;# Backward propagation.&lt;/span&gt;
	    &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;backward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	    &lt;span class=&quot;c&quot;&gt;# Update parameters.&lt;/span&gt;
	    &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To prepare the mini-batches, one most apply some preprocessing steps: randomizing the dataset in order to random split the dataset and then partitioning it in the right number of chunks. But what happens if we chose to set the number of batches to 1 or equal to the number of training examples?&lt;/p&gt;

&lt;h2 id=&quot;batch-gradient-descent&quot;&gt;&lt;strong&gt;Batch Gradient Descent&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;As stated before, in this gradient descent, each batch is equal to the entire dataset. That is:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/gradient-descent-variants/f2.png&quot; alt=&quot;math2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Where {1} denotes the first batch from the mini-batch. The downside is that it takes too long per iteration. This method can be used to training datasets with less than 2000 training examples.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;(Batch) Gradient Descent&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_input&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# Forward propagation&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# Compute cost.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compute_cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# Backward propagation.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;backward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# Update parameters.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;stochastic-gradient-descent&quot;&gt;&lt;strong&gt;Stochastic Gradient Descent&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;On other hand, in this method, each batch is equal to one example from the training set. In this example, the first mini-batch is equal to the first training example:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/gradient-descent-variants/f3.png&quot; alt=&quot;math3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Where (1) denotes the first training example. Here the downside is that it loses the advantage gained from vectorization, has more oscilation but converges faster.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Stochastic Gradient Descent&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_input&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# Forward propagation&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# Compute cost&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compute_cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# Backward propagation&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;backward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# Update parameters.&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;It is essential to understand the difference between these optimization algorithms, as they compose a key function for Neural Networks. In summary, although Batch GD has higher accuracy than Stochastic GD, the latter is faster. The middle ground of the two and the most adopted, Mini-batch GD, combine both to deliver good accuracy and good performance.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/gradient-descent-variants/batch-stochastic-mini-gd.png&quot; alt=&quot;Gradient descent variants&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Batch vs Stochastic vs Mini-batch Gradient Descent. Source: &lt;a href=&quot;https://www.coursera.org/learn/deep-neural-network/&quot;&gt;Stanford’s Andrew Ng’s MOOC Deep Learning Course&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;It is possible to use only the Mini-batch Gradient Descent code to implement all versions of Gradient Descent, you just need to set the mini_batch_size equals one to Stochastic GD or to the number of training examples to Batch GD. Thus, the main difference between Batch, Mini-batch and Stochastic Gradient Descent is the number of examples used for each epoch and the time and effort necessary to reach the global minimum value of the Cost Function.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Matheus Jacques</name>
        
        
      </author>

      

      
        <category term="back-to-basics" />
      
        <category term="gradient-descent" />
      

      
        <summary type="html">What is the difference between these three Gradient Descent variants?</summary>
      

      
      
    </entry>
  
</feed>
